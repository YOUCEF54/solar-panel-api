"""
Service Deep Learning pour pr√©dire l'√©tat de propret√© des panneaux solaires via images.
Utilise un mod√®le MobileNet entra√Æn√© pour la classification d'images.
"""

import tensorflow as tf
import numpy as np
import logging
from typing import Dict, Any, Optional, Tuple, Union
from pathlib import Path
from PIL import Image
import io
import base64

logger = logging.getLogger(__name__)

# Chemin vers le mod√®le DL
MODEL_DIR = Path(__file__).parent.parent.parent / "models" / "dl"
MODEL_PATH = MODEL_DIR / "mobilenet_solar_final.keras"

# Variable globale pour le mod√®le
_dl_model = None

# Taille d'image attendue par MobileNet (224x224 est standard pour MobileNet)
IMAGE_SIZE = (224, 224)

# Mapping des classes du mod√®le
DL_CLASS_NAMES = {
    0: "Bird-drop",
    1: "Clean",
    2: "Dusty",
    3: "Electrical-damage",
    4: "Physical-Damage",
    5: "Snow-Covered"
}

# Mapping des classes vers clean/dirty pour compatibilit√©
# Classes consid√©r√©es comme "clean": Clean
# Classes consid√©r√©es comme "dirty": Bird-drop, Dusty, Electrical-damage, Physical-Damage, Snow-Covered
DL_CLASS_TO_STATUS = {
    0: "dirty",   # Bird-drop
    1: "clean",   # Clean
    2: "Dusty",   # Dusty
    3: "Electrical-damage",   # Electrical-damage
    4: "Physical-damage",   # Physical-Damage
    5: "Snow-Covered"    # Snow-Covered
}


def load_dl_model() -> Optional[tf.keras.Model]:
    """
    Charge le mod√®le Deep Learning MobileNet depuis le fichier.
    
    Returns:
        Mod√®le Keras charg√© ou None en cas d'erreur
    """
    global _dl_model
    
    if _dl_model is not None:
        return _dl_model
    
    try:
        if not MODEL_PATH.exists():
            logger.error(f"‚ùå Fichier mod√®le DL introuvable: {MODEL_PATH}")
            return None
        
        logger.info(f"üì¶ Chargement du mod√®le DL depuis {MODEL_PATH}")
        _dl_model = tf.keras.models.load_model(str(MODEL_PATH))
        logger.info("‚úÖ Mod√®le DL charg√© avec succ√®s")
        
        # V√©rifier la taille d'image attendue
        input_shape = _dl_model.input_shape
        if input_shape and len(input_shape) >= 3:
            global IMAGE_SIZE
            IMAGE_SIZE = (input_shape[1], input_shape[2]) if input_shape[1] and input_shape[2] else (224, 224)
            logger.info(f"üìê Taille d'image attendue par le mod√®le: {IMAGE_SIZE}")
        
        return _dl_model
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du chargement du mod√®le DL: {e}", exc_info=True)
        return None


def preprocess_image(image: Union[str, Path, Image.Image, np.ndarray, bytes]) -> Optional[np.ndarray]:
    """
    Pr√©pare une image pour la pr√©diction.
    
    Args:
        image: Peut √™tre:
            - Chemin vers un fichier image (str ou Path)
            - Image PIL
            - Array numpy
            - Bytes d'une image
            - Base64 string encod√©e
    
    Returns:
        Array numpy pr√©process√© pour le mod√®le ou None en cas d'erreur
    """
    try:
        # Charger l'image selon le type d'entr√©e
        if isinstance(image, (str, Path)):
            # Chemin de fichier
            img_path = Path(image)
            if not img_path.exists():
                logger.error(f"‚ùå Fichier image introuvable: {img_path}")
                return None
            logger.debug(f"üì∑ Chargement de l'image: {img_path}")
            img = Image.open(img_path)
            logger.debug(f"   Taille originale: {img.size}, Mode: {img.mode}")
            
        elif isinstance(image, Image.Image):
            # Image PIL d√©j√† charg√©e
            img = image
            logger.debug(f"üì∑ Image PIL re√ßue, Taille: {img.size}, Mode: {img.mode}")
            
        elif isinstance(image, np.ndarray):
            # Array numpy - convertir en Image PIL
            img = Image.fromarray(image)
            logger.debug(f"üì∑ Conversion numpy -> PIL, Taille: {img.size}")
            
        elif isinstance(image, bytes):
            # Bytes d'une image
            img = Image.open(io.BytesIO(image))
            logger.debug(f"üì∑ Image depuis bytes, Taille: {img.size}")
            
        elif isinstance(image, str):
            # Peut √™tre du base64
            try:
                # Essayer de d√©coder en base64
                image_bytes = base64.b64decode(image)
                img = Image.open(io.BytesIO(image_bytes))
                logger.debug(f"üì∑ Image depuis base64, Taille: {img.size}")
            except Exception:
                logger.error("‚ùå Format d'image non reconnu (attendu: chemin de fichier, PIL Image, numpy array, bytes, ou base64)")
                return None
        else:
            logger.error(f"‚ùå Type d'image non support√©: {type(image)}")
            return None
        
        # Convertir en RGB si n√©cessaire
        if img.mode != 'RGB':
            logger.debug(f"   Conversion de {img.mode} vers RGB")
            img = img.convert('RGB')
        
        # Redimensionner √† la taille attendue
        img_resized = img.resize(IMAGE_SIZE, Image.Resampling.LANCZOS)
        logger.debug(f"   Image redimensionn√©e √†: {IMAGE_SIZE}")
        
        # Convertir en array numpy
        img_array = np.array(img_resized, dtype=np.float32)
        
        # Normalisation: le mod√®le pourrait avoir √©t√© entra√Æn√© avec ou sans normalisation ImageNet
        # Par d√©faut, on essaie SANS normalisation ImageNet (juste [0,1])
        # Si les pr√©dictions sont incorrectes, essayez avec USE_IMAGENET_NORMALIZATION = True
        
        USE_IMAGENET_NORMALIZATION = False  # Changez en True si le mod√®le le n√©cessite
        
        if USE_IMAGENET_NORMALIZATION:
            # Normaliser [0, 1] puis appliquer ImageNet normalization
            img_array = img_array / 255.0
            # Valeurs moyennes ImageNet pour chaque canal RGB
            imagenet_mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)
            imagenet_std = np.array([0.229, 0.224, 0.225], dtype=np.float32)
            # Normaliser avec les valeurs ImageNet par canal
            for i in range(3):
                img_array[:, :, i] = (img_array[:, :, i] - imagenet_mean[i]) / imagenet_std[i]
            logger.debug(f"   Normalisation ImageNet appliqu√©e")
        else:
            # Normaliser simplement [0, 1]
            img_array = img_array / 255.0
            logger.debug(f"   Normalisation simple [0,1] appliqu√©e")
        
        # V√©rifier les valeurs min/max pour debugging
        logger.debug(f"   Valeurs min/max du array: {img_array.min():.4f} / {img_array.max():.4f}")
        
        # Ajouter la dimension du batch
        img_array = np.expand_dims(img_array, axis=0)
        
        logger.debug(f"   Shape final: {img_array.shape}")
        
        return img_array
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du pr√©traitement de l'image: {e}", exc_info=True)
        return None


def predict_from_image(image: Union[str, Path, Image.Image, np.ndarray, bytes]) -> Optional[Dict[str, Any]]:
    """
    Pr√©dit l'√©tat de propret√© d'un panneau solaire √† partir d'une image.

    Args:
        image: Image √† analyser (peut √™tre chemin de fichier, PIL Image, numpy array, bytes, ou base64)

    Returns:
        Dictionnaire avec:
            - dl_prediction: str (nom de la classe pr√©dite, ex: "Physical-Damage")
            - dl_status: str ("clean" ou "dirty")
            - dl_confidence: float (probabilit√© de la classe pr√©dite)
            - dl_probability: dict avec "clean" et "dirty" comme cl√©s
            - dl_class_probabilities: dict avec les probabilit√©s de chaque classe par nom
            - dl_predicted_class: int (index de la classe pr√©dite, 0-5)
        ou None en cas d'erreur
    """
    try:
        # Charger le mod√®le si n√©cessaire
        model = load_dl_model()

        if model is None:
            logger.warning("‚ö†Ô∏è Mod√®le DL non disponible - utilisation du mode mock pour les tests")
            # Return mock prediction for testing when model is not available
            return {
                "dl_mock": True,  # Flag to indicate this is mock data
                "dl_prediction": "Clean",  # Mock prediction
                "dl_status": "clean",
                "dl_confidence": 0.85,  # Mock confidence
                "dl_probability": {
                    "clean": 0.85,
                    "dirty": 0.15
                },
                "dl_class_probabilities": {
                    "Clean": 0.85,
                    "Dusty": 0.10,
                    "Bird-drop": 0.03,
                    "Electrical-damage": 0.01,
                    "Physical-Damage": 0.005,
                    "Snow-Covered": 0.005
                },
                "dl_predicted_class": 1  # Index for Clean class
            }
        
        # Pr√©processer l'image
        processed_image = preprocess_image(image)
        if processed_image is None:
            return None
        
        # Faire la pr√©diction
        logger.debug(f"ü§ñ Pr√©diction en cours avec le mod√®le...")
        predictions = model.predict(processed_image, verbose=0)
        
        # G√©rer diff√©rentes configurations de sortie
        if len(predictions.shape) != 2:
            logger.error(f"‚ùå Format de pr√©diction non attendu: {predictions.shape}")
            return None
        
        num_classes = predictions.shape[1]
        prediction_probs = predictions[0]
        
        # Afficher toutes les probabilit√©s pour debugging
        logger.debug(f"üìä Probabilit√©s brutes: {prediction_probs}")
        
        # Trouver la classe pr√©dite (celle avec la probabilit√© la plus √©lev√©e)
        prediction_class = int(np.argmax(prediction_probs))
        confidence = float(prediction_probs[prediction_class])
        
        logger.debug(f"   Classe pr√©dite (index): {prediction_class}, Confiance: {confidence:.4f}")
        
        # Obtenir le nom de la classe pr√©dite
        predicted_class_name = DL_CLASS_NAMES.get(prediction_class, f"Class-{prediction_class}")
        
        # Cr√©er un dictionnaire avec les probabilit√©s de chaque classe par nom
        class_probabilities = {}
        for class_idx in range(num_classes):
            class_name = DL_CLASS_NAMES.get(class_idx, f"Class-{class_idx}")
            class_probabilities[class_name] = float(prediction_probs[class_idx])
        
        # Calculer clean/dirty bas√© sur le mapping des classes
        if num_classes == 6:
            # Mod√®le avec 6 classes - utiliser le mapping d√©fini
            probability_clean = sum(
                float(prediction_probs[i]) 
                for i in range(num_classes) 
                if DL_CLASS_TO_STATUS.get(i, "dirty") == "clean"
            )
            probability_dirty = sum(
                float(prediction_probs[i]) 
                for i in range(num_classes) 
                if DL_CLASS_TO_STATUS.get(i, "dirty") == "dirty"
            )
            
            # D√©terminer le statut bas√© sur la classe pr√©dite
            dl_status = DL_CLASS_TO_STATUS.get(prediction_class, "dirty")
            
            logger.debug(f"üìä 6 classes d√©tect√©es:")
            for class_idx, class_name in DL_CLASS_NAMES.items():
                logger.debug(f"   {class_name} (class {class_idx}): {prediction_probs[class_idx]:.4f}")
            logger.debug(f"   Classe pr√©dite: {prediction_class} ({predicted_class_name}) -> {dl_status}")
        elif num_classes == 2:
            # Cas binaire classique
            probability_clean = float(prediction_probs[0])
            probability_dirty = float(prediction_probs[1])
            dl_status = "dirty" if prediction_class == 1 else "clean"
            predicted_class_name = "Clean" if prediction_class == 0 else "Dirty"
        elif num_classes == 1:
            # Cas sigmoid (une seule probabilit√©)
            probability_dirty = float(prediction_probs[0])
            probability_clean = 1.0 - probability_dirty
            dl_status = "dirty" if probability_dirty > 0.5 else "clean"
            predicted_class_name = "Dirty" if dl_status == "dirty" else "Clean"
        else:
            # Cas g√©n√©rique pour n'importe quel nombre de classes
            split_point = num_classes // 2
            probability_clean = float(np.sum(prediction_probs[:split_point]))
            probability_dirty = float(np.sum(prediction_probs[split_point:]))
            dl_status = "dirty" if prediction_class >= split_point else "clean"
            predicted_class_name = DL_CLASS_NAMES.get(prediction_class, f"Class-{prediction_class}")
            logger.warning(f"‚ö†Ô∏è Nombre de classes non standard ({num_classes}), utilisation de mapping g√©n√©rique")
        
        # S'assurer que les probabilit√©s totalisent 1.0 (normalisation)
        total_prob = probability_clean + probability_dirty
        if abs(total_prob - 1.0) > 0.01:  # Tol√©rance pour erreurs d'arrondi
            # Renormaliser si n√©cessaire
            probability_clean = probability_clean / total_prob if total_prob > 0 else 0.5
            probability_dirty = probability_dirty / total_prob if total_prob > 0 else 0.5
        
        result = {
            "dl_prediction": predicted_class_name,  # Nom de la classe pr√©dite (ex: "Physical-Damage")
            "dl_status": dl_status,  # Statut clean/dirty
            "dl_confidence": confidence,  # Probabilit√© de la classe pr√©dite
            "dl_probability": {
                "clean": probability_clean,
                "dirty": probability_dirty
            },
            "dl_class_probabilities": class_probabilities,  # Probabilit√©s de chaque classe par nom
            "dl_predicted_class": int(prediction_class)  # Index de la classe pr√©dite (0-5)
        }
        
        logger.info(f"‚úÖ Pr√©diction DL: {predicted_class_name} ({dl_status}, confiance: {confidence:.2%})")
        
        return result
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de la pr√©diction DL: {e}", exc_info=True)
        return None


def is_dl_model_loaded() -> bool:
    """V√©rifie si le mod√®le DL est charg√©."""
    global _dl_model
    return _dl_model is not None

